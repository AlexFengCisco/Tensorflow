{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST tensorflow Machine Learning note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    MNIST is a canonical dataset for machine learning test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules ,load MNIST dataset and start interactive session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#load MNIST data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "#mnist ia a lightweight class , includes training validation and testing dataset in umpy array mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convenient when working with interactive contexts like ipython\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])  #MNIST 28x28 pixels \n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])  #10 dimentional verctor indicates real digit 1-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#initial Weight and bias by filling of zeros\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print W.eval()\n",
    "print b.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Softmax Regression Model\n",
    "    Simply we can call it no hidden layer network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define regression model\n",
    "y = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#specify loss function\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#specify train model\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 corss_entropy 2.020794\n",
      "step 50 corss_entropy 0.529039\n",
      "step 100 corss_entropy 0.404912\n",
      "step 150 corss_entropy 0.381642\n",
      "step 200 corss_entropy 0.365754\n",
      "step 250 corss_entropy 0.347816\n",
      "step 300 corss_entropy 0.341887\n",
      "step 350 corss_entropy 0.329071\n",
      "step 400 corss_entropy 0.326172\n",
      "step 450 corss_entropy 0.323355\n",
      "step 500 corss_entropy 0.317942\n",
      "step 550 corss_entropy 0.319675\n",
      "step 600 corss_entropy 0.328030\n",
      "step 650 corss_entropy 0.318455\n",
      "step 700 corss_entropy 0.305990\n",
      "step 750 corss_entropy 0.304117\n",
      "step 800 corss_entropy 0.305624\n",
      "step 850 corss_entropy 0.298308\n",
      "step 900 corss_entropy 0.305628\n",
      "step 950 corss_entropy 0.298876\n",
      "step 1000 corss_entropy 0.292583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120318e90>]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU0SSJEmSJEmSJEmSJEmSJEmSJEmSVPH/RDdB5qwjGx0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cc891d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px = []\n",
    "py = []\n",
    "for i in range(1001):\n",
    "  \n",
    "  batch = mnist.train.next_batch(100)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "  if i%50 == 0:\n",
    "    c_ep=cross_entropy.eval(feed_dict={x: mnist.train.images,y_: mnist.train.labels})\n",
    "    print(\"step %d corss_entropy %f\"% (i,c_ep))\n",
    "    px.append(i)\n",
    "    py.append(c_ep)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(px,py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[-0.37697944  0.33022499  0.08318686 -0.2426587   0.02532654  1.33719277\n",
      " -0.11185047  0.63854933 -1.45174158 -0.23124941]\n"
     ]
    }
   ],
   "source": [
    "print W.eval()\n",
    "print b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185\n",
      "[ True  True  True ...,  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "# .eval means this is an interactive session \n",
    "print(correct_prediction.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "#some of the result is False  , so the prediction accuracy is around 91.x% \n",
    "#is a BAD accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Multilayer Convolutional Network\n",
    "    Multilayers netowrks can compose more features and make A better  prediction accuracy .\n",
    "    \n",
    "    MNIST iamge input 28x28x1 \n",
    "    1st convolutional layer , 28x28x32 (filter size 5x5 stride [1,1] output deepth 32)\n",
    "    1st pooling layer ,14x14x32 (filter size 2x2 stride [2,2])\n",
    "    2nd convolutional layer , 14x14x64 (filter 5x5 stide 1,1 output deepth 64)\n",
    "    2nd pooling layer ,7x7x64 ,(filter same)\n",
    "    2nd pooling flat = 7x7x64 = 3136   flat layer\n",
    "    full connection layer = 1024 (after activation funvtion ReLu\n",
    "    full connection layer dropout rate 0.5\n",
    "    final_output flat layer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weights and biases initialization...\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define convolution and pooling function\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')#usually ,pooling filter size 2x2 or 3x3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The convolution will compute 32 features for each 5x5 patch. \n",
    "Its weight tensor will have a shape of [5, 5, 1, 32]. \n",
    "The first two dimensions are the patch size, the next is the number of input channels,\n",
    "and the last is the number of output channels\n",
    "\n",
    "it means , the filter size is 5x5  , \n",
    "input layer has 2 dimensions, 28x28x1 (mono ,no RGB color channels ) ,1 as input layer deepth\n",
    "and 32 is output deepth\n",
    "\n",
    "for output convolutional layer width and length , 28-5+1=24 /1 = 24  (if filter stride = 1 )\n",
    "output_length=[ (input_length-filter_length +1)/stride_length ] --->when padding is VALID \n",
    "\n",
    "In this case. padding = \"SAME\" , output_length = input_length/stride =28/1= 28\n",
    "\n",
    "bias numbers = output layer deepth\n",
    "'''\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # filter size 5x5 ,strides [1,1] , padding =VALID\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.08\n",
      "step 500, training accuracy 0.96\n",
      "step 1000, training accuracy 0.94\n",
      "step 1500, training accuracy 0.96\n",
      "step 2000, training accuracy 0.98\n",
      "step 2500, training accuracy 0.98\n",
      "step 3000, training accuracy 1\n",
      "step 3500, training accuracy 1\n",
      "step 4000, training accuracy 1\n",
      "step 4500, training accuracy 0.98\n",
      "step 5000, training accuracy 0.98\n",
      "step 5500, training accuracy 1\n",
      "step 6000, training accuracy 1\n",
      "step 6500, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 7500, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 8500, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 9500, training accuracy 0.98\n",
      "test accuracy 0.9904\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for i in range(10000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 500 == 0:\n",
    "      train_accuracy = accuracy.eval(feed_dict={\n",
    "          x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "      print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "  print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "      x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    After 10000 steps trsaining , the test acurracy is 99% ,much better than a no hiddenlayer neural network ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
